# -*- coding: utf-8 -*-
"""McDonald_s_Food_Reviews.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RP0xFaP-PKRLAxWN5sb0XAmpTo5hN5of
"""

#libraries
import numpy as np
import pandas as pd
# from google.colab import drive
import unicodedata
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import re
import nltk
from nltk.corpus import wordnet
from nltk.stem import PorterStemmer
from sklearn.preprocessing import LabelEncoder
from nltk.sentiment import SentimentIntensityAnalyzer
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from sklearn.model_selection import train_test_split
from sklearn.svm import LinearSVC
from sklearn import svm
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import Pipeline
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import VotingClassifier
import joblib

# drive.mount('/content/gdrive')
# data_set = pd.read_csv('/content/gdrive/MyDrive/McDonald_s_Food_Reviews.csv',encoding='latin-1')

data_set = pd.read_csv('D:\PYTHON PROJECTS\CSD\McDonald_s_Food_Reviews.csv',encoding='latin-1')

# Print first 5 rows
print("Top 5 rows of dataset")
print(data_set.describe())

# Print random 10 rows
print("Random 10 rows")
print(data_set.sample(10))

# Print total number of rows and columns in dataset
print("Total rows and columns in dataset")
print(data_set.shape)

# Print number of rows and columns in dataset separately
print("Total Rows =", data_set.shape[0])
print("Total Columns =", data_set.shape[1])

print("Columns in dataset")
print(data_set.columns)

#Check information of dataset
print("Dataset information")
print(data_set.info())

# Drop unnecessary columns

print("Dropping extra columns")
columns_to_drop = ['store_name', 'category', 'latitude ', 'longitude']
data_set.drop(columns=columns_to_drop, inplace=True)  # Use inplace=True to modify data_set in place

data_set.describe()

data_set.head()

#Check for duplicate values
print("Checking for duplicate data")
print("Total Duplicated values =", data_set.duplicated().sum())

#Check for null values
print("Checking for null values")
print("Total NULL values =\n\n",data_set.isnull().sum())

print("Sort by no of ratings")
print(data_set['rating'].value_counts())

# nltk.download('stopwords')



"""Text -> Convert Accented Characters -> Tokenization -> Stopwords Removal -> Removing Numbers and Extra Whitespaces -> Lemmatization -> Stemming -> Removing Single Letters"""

stopwords_set = set(stopwords.words('english'))
def processing(text):

    # Step 1: Remove Accented Characters
    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')

    # Step 2: Tokenization
    tokens = word_tokenize(text)

    # Step 3: Stopwords Removal
    stop_words = set(stopwords.words('english'))
    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]

    # Step 4: Remove Numbers and Extra Whitespaces
    filtered_tokens = [re.sub(r'\d+', '', word) for word in filtered_tokens]
    filtered_tokens = [word.strip() for word in filtered_tokens if word.strip()]

    # Step 5: Lemmatization
    lemmatizer = WordNetLemmatizer()
    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]

    # Step 6: Stemming (optional)
    stemmer = PorterStemmer()
    stemmed_tokens = [stemmer.stem(word) for word in lemmatized_tokens]

    # Step 7: Remove Single Letters
    filtered_tokens = [word for word in stemmed_tokens if len(word) > 1]

    # Join the tokens back into a clean text string
    clean_text = ' '.join(filtered_tokens)


    return clean_text

# Example text with unreadable characters
# text = "Worst McDonaldï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿"
# clean_text="Worst McDonald"

# def convert_time_to_days(time_str):
#     time_str=str(time_str)
#     if "month" in time_str:
#       if time_str[0] == "a":
#         return 30
#       else:
#         return 30*int(time_str[0])
#     elif "year" in time_str:
#       if time_str[0] == "a":
#         return 365
#       else:
#         return 365*int(time_str[0])
#     elif "week" in time_str:
#       if time_str[0] == "a":
#         return 7
#       else:
#         return 7*int(time_str[0])
#     elif "day" in time_str:
#       if time_str[0] == "a":
#         return 1
#       else:
#         return int(time_str[0])
#     else:
#         return None

i=0
for reviews in data_set['review']:
  data_set.at[i,'review'] = processing(reviews)
  # data_set.at[i,'rating']= data_set.at[i,'rating'][0]
  # data_set.at[i,'review_time'] = convert_time_to_days(data_set.at[i,'review_time'])
  # print(convert_time_to_days(data_set.at[i,'review_time']))
  # if i==5:
  #   break
  i+=1
data_set.head()

random_sample = data_set.sample(n=20, random_state=42)
random_sample

sia = SentimentIntensityAnalyzer()
sentiments = []

# text_weight = 0.6
# time_weight = 0.2
# count_weight = 0.1
# store_weight = 0.1

# for index, row in data_set.iterrows():
#     compound_score = 0.0  # Initialize the compound score for each row

#     # Iterate through the columns dynamically
#     for column in data_set.columns:
#         if column == 'review':
#             text = row[column]
#             sentiment = sia.polarity_scores(text)
#             compound_score += (text_weight * sentiment['compound'])
#         elif column == 'review_time':
#             time = row[column]
#             sentiment = sia.polarity_scores(time)
#             compound_score += (time_weight * sentiment['compound'])
#         elif column == 'rating_count':
#             count = row[column]
#             sentiment = sia.polarity_scores(count)
#             compound_score += (count_weight * sentiment['compound'])
#         elif column == 'store_address':
#             address = row[column]
#             sentiment = sia.polarity_scores(address)
#             compound_score += (store_weight * sentiment['compound'])
#         else:
#             # You can handle other columns as needed
#             pass

#     sentiments.append(compound_score)


for review in data_set['review']:
    sentiment = sia.polarity_scores(review)
    sentiments.append(sentiment)

i=0
while i!=10:
  print(sentiments[i])
  i+=1

sentiment_labels = []

for sentiment in sentiments:
    compound_score = sentiment['compound']
    # compound_score = sentiment
    if compound_score >= 0.05:
        sentiment_labels.append(1)
    elif compound_score <= -0.05:
        sentiment_labels.append(-1)
    else:
        sentiment_labels.append(0)

# Add the sentiment labels to the DataFrame

#PPNONPPNPP
data_set['sentiment'] = sentiment_labels
data_set[['review', 'sentiment']]

X = data_set['review']
y = data_set['sentiment']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

vectorizer = TfidfVectorizer()
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# Create a LinearSVC model
linear_svc_model = LinearSVC()

# Fit the model to the TF-IDF training data
linear_svc_model.fit(X_train_tfidf, y_train)

# Predict on the TF-IDF test data
linear_svc_y_pred = linear_svc_model.predict(X_test_tfidf)

# Calculate accuracy and print the results
linear_svc_accuracy = accuracy_score(y_test, linear_svc_y_pred)
print("LinearSVC Accuracy:", linear_svc_accuracy)
print("Classification Report:")
print(classification_report(y_test, linear_svc_y_pred))

# Create a MultinomialNB model
naive_bayes_model = MultinomialNB()

# Fit the model to the TF-IDF training data
naive_bayes_model.fit(X_train_tfidf, y_train)

# Predict on the TF-IDF test data
naive_bayes_y_pred = naive_bayes_model.predict(X_test_tfidf)

# Calculate accuracy and print the results
naive_bayes_accuracy = accuracy_score(y_test, naive_bayes_y_pred)
print("Multinomial Naive Bayes Accuracy:", naive_bayes_accuracy)
print("Classification Report:")
print(classification_report(y_test, naive_bayes_y_pred))

# Create a Logistic Regression model
logistic_regression_model = LogisticRegression()

# Fit the model to the TF-IDF training data
logistic_regression_model.fit(X_train_tfidf, y_train)

# Predict on the TF-IDF test data
logistic_regression_y_pred = logistic_regression_model.predict(X_test_tfidf)

# Calculate accuracy and print the results
logistic_regression_accuracy = accuracy_score(y_test, logistic_regression_y_pred)
print("Logistic Regression Accuracy:", logistic_regression_accuracy)
print("Classification Report:")
print(classification_report(y_test, logistic_regression_y_pred))

# Create a Random Forest model
random_forest_model = RandomForestClassifier()

# Fit the model to the TF-IDF training data
random_forest_model.fit(X_train_tfidf, y_train)

# Predict on the TF-IDF test data
random_forest_y_pred = random_forest_model.predict(X_test_tfidf)

# Calculate accuracy and print the results
random_forest_accuracy = accuracy_score(y_test, random_forest_y_pred)
print("Random Forest Accuracy:", random_forest_accuracy)
print("Classification Report:")
print(classification_report(y_test, random_forest_y_pred))

model1 = LinearSVC()
model2 = MultinomialNB()
model3 = LogisticRegression()

ensemble_model = VotingClassifier(
    estimators=[('model1', model1), ('model2', model2), ('model3', model3)],
    voting='hard'  # You can choose 'hard' or 'soft' voting depending on your use case
)


# Fit the ensemble model on the training data
ensemble_model.fit(X_train_tfidf, y_train)

# Make predictions using the ensemble model
y_pred = ensemble_model.predict(X_test_tfidf)

# Evaluate the performance of the ensemble model (you can use different metrics)
accuracy = accuracy_score(y_test, y_pred)
print(f'Ensemble Model Accuracy: {accuracy:.2f}')

# Finally, you can use the trained ensemble model to make predictions on your test data
y_test_pred = ensemble_model.predict(X_test_tfidf)

# Save the ensemble model
joblib.dump(ensemble_model, 'ensemble_model.joblib')
joblib.dump(vectorizer, 'tfidf_vectorizer.joblib')

loaded_model = joblib.load('ensemble_model.joblib')
loaded_vectorizer = joblib.load('tfidf_vectorizer.joblib')
Input="The delectable aroma of the freshly baked bread filled the air as I stepped into the cozy bakery. The warm, crusty baguette I ordered was a delightful treat. It had a perfect crunch on the outside and a soft, airy interior. Absolutely delicious!"
input_vector = loaded_vectorizer.transform([processing(Input)])
predicted_rating = loaded_model.predict(input_vector)
print("Predicted Rating:", predicted_rating)

"""##gpt prompt

give me food review inputs to check if my model is good or not give one positive one neutral and one negative inputs and make inputs so hard to guess so i can check my classifier

Sure, here are some food review inputs with varying sentiments for testing your classifier:

Positive Review:

Input: "The delectable aroma of the freshly baked bread filled the air as I stepped into the cozy bakery. The warm, crusty baguette I ordered was a delightful treat. It had a perfect crunch on the outside and a soft, airy interior. Absolutely delicious!"


Neutral Review:

Input: "I visited the restaurant last night. The service was decent, and the ambiance was pleasant. However, the food was just average. It didn't stand out, but it wasn't terrible either."


Negative Review:

Input: "My experience at the restaurant was highly disappointing. The waitstaff seemed disinterested, and it took forever to get our orders. When the food finally arrived, it was cold, tasteless, and overpriced. I won't be returning."
These reviews cover a range of sentiments from positive to neutral to negative. You can use these inputs to check how your classifier predicts the sentiment of each review and evaluate its performance.
"""











# #Vectorizing the Words
# tf_vec = TfidfVectorizer()
# #['store address','rating_count','review_time','review']
# features = tf_vec.fit_transform(data_set['store address','rating_count','review_time','review'])
# X = features
# y = data_set['rating']


# vect=TfidfVectorizer()
# StoreAddress=vect.fit_transform(data_set['store_address'])
# Review=vect.fit_transform(data_set['review'])

# X_numerical = data_set[['rating_count', 'review_time']].values

# X_combined = np.hstack((X_numerical, StoreAddress.toarray(), Review.toarray()))


# X = np.asarray(data_set[['store_address','rating_count','review_time','review']])
# Y = np.asarray(data_set['rating'])

# label_encoder = LabelEncoder()
# data_set['rating'] = label_encoder.fit_transform(data_set['rating'])

# #Splitting the Dataset into Train and Test Sets

# X = data_set[['store_address', 'rating_count', 'review_time', 'review']]
# y = data_set['rating']

# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# # LinearSVC
# linear_svc_model = Pipeline([
#     ('vectorizer', CountVectorizer()),
#     ('tfidf', TfidfTransformer()),
#     ('clf', LinearSVC())
# ])

# # Naive Bayes
# naive_bayes_model = Pipeline([
#     ('vectorizer', CountVectorizer()),
#     ('tfidf', TfidfTransformer()),
#     ('clf', MultinomialNB())
# ])

# # Logistic Regression
# logistic_regression_model = Pipeline([
#     ('vectorizer', CountVectorizer()),
#     ('tfidf', TfidfTransformer()),
#     ('clf', LogisticRegression(max_iter=1000))
# ])

# random_forest_model = Pipeline([
#     ('vectorizer', CountVectorizer()),
#     ('tfidf', TfidfTransformer()),
#     ('clf', RandomForestClassifier())  # Use RandomForestClassifier here
# ])

# decision_tree_model = Pipeline([
#     ('vectorizer', CountVectorizer()),
#     ('tfidf', TfidfTransformer()),
#     ('clf', DecisionTreeClassifier())  # Use DecisionTreeClassifier here
# ])

# # Fit and evaluate the LinearSVC model
# linear_svc_model.fit(X_train['review'], y_train)
# linear_svc_predictions = linear_svc_model.predict(X_test['review'])
# linear_svc_accuracy = accuracy_score(y_test, linear_svc_predictions)
# linear_svc_confusionmatrix = confusion_matrix(y_test, linear_svc_predictions)
# linear_svc_classificationreport = classification_report(y_test, linear_svc_predictions)

# # Fit and evaluate the Naive Bayes model
# naive_bayes_model.fit(X_train['review'], y_train)
# naive_bayes_predictions = naive_bayes_model.predict(X_test['review'])
# naive_bayes_accuracy = accuracy_score(y_test, naive_bayes_predictions)
# naive_bayes_confusionmatrix = confusion_matrix(y_test, naive_bayes_predictions)
# naive_bayes_classificationreport = classification_report(y_test, naive_bayes_predictions)

# # Fit and evaluate the Logistic Regression model
# logistic_regression_model.fit(X_train['review'], y_train)
# logistic_regression_predictions = logistic_regression_model.predict(X_test['review'])
# logistic_regression_accuracy = accuracy_score(y_test, logistic_regression_predictions)
# logistic_regression_confusionmatrix = confusion_matrix(y_test, logistic_regression_predictions)
# logistic_regression_classificationreport = classification_report(y_test, logistic_regression_predictions)

# print("LinearSVC Metrics:")
# print(f"Accuracy: {linear_svc_accuracy}")
# print("Confusion Matrix:")
# print(linear_svc_confusionmatrix)
# print("Classification Report:")
# print(linear_svc_classificationreport)
# print("\n")

# print("Naive Bayes Metrics:")
# print(f"Accuracy: {naive_bayes_accuracy}")
# print("Confusion Matrix:")
# print(naive_bayes_confusionmatrix)
# print("Classification Report:")
# print(naive_bayes_classificationreport)
# print("\n")

# print("Logistic Regression Metrics:")
# print(f"Accuracy: {logistic_regression_accuracy}")
# print("Confusion Matrix:")
# print(logistic_regression_confusionmatrix)
# print("Classification Report:")
# print(logistic_regression_classificationreport)

# # Fit and evaluate the Random Forest model
# random_forest_model.fit(X_train['review'], y_train)
# random_forest_predictions = random_forest_model.predict(X_test['review'])
# random_forest_accuracy = accuracy_score(y_test, random_forest_predictions)
# random_forest_confusionmatrix = confusion_matrix(y_test, random_forest_predictions)
# random_forest_classificationreport = classification_report(y_test, random_forest_predictions)

# # Print the metrics for the Random Forest model
# print("Random Forest Metrics:")
# print(f"Accuracy: {random_forest_accuracy}")
# print("Confusion Matrix:")
# print(random_forest_confusionmatrix)
# print("Classification Report:")
# print(random_forest_classificationreport)

# # Fit and evaluate the Decision Tree model
# decision_tree_model.fit(X_train['review'], y_train)
# decision_tree_predictions = decision_tree_model.predict(X_test['review'])
# decision_tree_accuracy = accuracy_score(y_test, decision_tree_predictions)
# decision_tree_confusionmatrix = confusion_matrix(y_test, decision_tree_predictions)
# decision_tree_classificationreport = classification_report(y_test, decision_tree_predictions)

# # Print the metrics for the Decision Tree model
# print("Decision Tree Metrics:")
# print(f"Accuracy: {decision_tree_accuracy}")
# print("Confusion Matrix:")
# print(decision_tree_confusionmatrix)
# print("Classification Report:")
# print(decision_tree_classificationreport)

# # Save the models to a file
# joblib.dump(linear_svc, 'linear_svc_model.joblib')
# joblib.dump(naive_bayes, 'naive_bayes_model.joblib')
# joblib.dump(logistic_regression, 'logistic_regression_model.joblib')

# loaded_model = joblib.load('naive_bayes_model.joblib')
# Input=input("Enter an input  : ")
# input_vector = tf_vec.transform([processing(Input)])
# predicted_rating = loaded_model.predict(input_vector)[0]
# print("Predicted Rating:", predicted_rating)

# loaded_model = joblib.load('linear_svc_model.joblib')
# Input=input("Enter an input  : ")
# input_vector = tf_vec.transform([processing(Input)])
# predicted_rating = loaded_model.predict(input_vector)[0]
# print("Predicted Rating:", predicted_rating)

# loaded_model = joblib.load('logistic_regression_model.joblib')
# Input=input("Enter an input  : ")
# input_vector = tf_vec.transform([processing(Input)])
# predicted_rating = loaded_model.predict(input_vector)[0]
# print("Predicted Rating:", predicted_rating)